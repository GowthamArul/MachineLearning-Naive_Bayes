# MachineLearning-Naive_Bayes

## Naive Bayes

1. NaÃ¯ve Bayes is a classification technique based on Bayesâ€™ Theorem.
2. Letâ€™s assume that you are data scientist working major bank in NYC and you want to classify a new client as eligible to retire or not.
3. Customer features are his/her age and salary.

### PRIOR PROBABILITY

1. Points can be classified as RED or BLUE. 
2. Our task is to classify a new point to RED or BLUE.
3. Prior Probability: Since we have more BLUE compared to RED, we can assume that our new point is twice as likely to be BLUE than RED. 

ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘“ğ‘œğ‘Ÿ ğ‘…ğ¸ğ·=(ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘…ğ¸ğ· ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )/(ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )=20/60

ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘“ğ‘œğ‘Ÿ ğµğ¿ğ‘ˆğ¸=(ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğµğ¿ğ‘ˆğ¸ ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )/(ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )=40/60

### LIKELIHOOD

1. For the new point, if there are more BLUE points in its vicinity, it is more likely that the new point will be classified as BLUE. 
2. So we draw a circle around the point
3. Then we calculate the number of points in the circle belonging to each class label.

ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğ‘…ğ¸ğ·=(ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘…ğ¸ğ· ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘  ğ‘–ğ‘› ğ‘£ğ‘–ğ‘ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘¦ )/(ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘…ğ¸ğ· ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )=3/20

ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğµğ¿ğ‘ˆğ¸=(ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğµğ¿ğ‘ˆğ¸ ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘  ğ‘–ğ‘› ğ‘£ğ‘–ğ‘ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘¦ )/(ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğµğ¿ğ‘ˆğ¸ ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘ )=1/40

### POSTERIOR PROBABILITY

1. Letâ€™s combine prior probability and likelihood to create a posterior probability. 
2. Prior probabilities: suggests that X may be classified as BLUE Because there are twice as much blue points.
3. Likelihood: suggests that X is RED because there are more RED points in the vicinity of X.
4. Bayesâ€™ Rule combines both to form a posterior probability.

ğ‘ƒğ‘œğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğ‘…ğ¸ğ·= ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘œğ‘“ ğ‘…ğ¸ğ· âˆ—ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğ‘…ğ¸ğ·=20/60âˆ—3/20=1/20  

ğ‘ƒğ‘œğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğµğ¿ğ‘ˆğ¸= ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘œğ‘“ ğµğ¿ğ‘ˆğ¸âˆ—ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ ğ‘œğ‘“ ğ‘‹ ğ‘ğ‘’ğ‘–ğ‘›ğ‘” ğµğ¿ğ‘ˆğ¸=40/60âˆ—1/40=1/60  

## To Get Clear Understanding, Refer the Power Points
